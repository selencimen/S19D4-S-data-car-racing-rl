{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9372b994",
   "metadata": {},
   "source": [
    "## ğŸï¸ Araba YarÄ±ÅŸÄ±\n",
    "\n",
    "---\n",
    "\n",
    "Bu projede, Gymnasium'dan [Car Racing ortamÄ±](https://gymnasium.farama.org/environments/box2d/car_racing/) ile Ã§alÄ±ÅŸacaksÄ±nÄ±z. GÃ¶rev, prosedÃ¼rel olarak oluÅŸturulan bir pistte arabayla sÃ¼rÃ¼ÅŸ yaparak, yolda kalÄ±rken turlarÄ± verimli bir ÅŸekilde tamamlamaktÄ±r.\n",
    "\n",
    "Ä°ki tÃ¼r pekiÅŸtirmeli Ã¶ÄŸrenme ajanÄ± eÄŸiteceksiniz: bir **DQN ajanÄ±** ve bir **PPO ajanÄ±**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš§ Bu Projeyi FarklÄ± KÄ±lan Nedir?\n",
    "\n",
    "**CliffWalking** gibi **ayrÄ±k eylem uzaylarÄ±** kullanan Ã¶nceki ortamlarÄ±n aksine, Car Racing ortamÄ± **sÃ¼rekli eylem uzayÄ±** kullanÄ±r.\n",
    "\n",
    "- Ajanlar ÅŸunlarÄ± kontrol etmeli:\n",
    "  - **Direksiyon** (sol/saÄŸ)\n",
    "  - **HÄ±zlanma** (gaz)\n",
    "  - **Fren yapma**\n",
    "\n",
    "Bu ÅŸu anlama gelir:\n",
    "- âŒ DQN, ince ayarlÄ± sÃ¼rekli kontrolde zorlanÄ±r  \n",
    "- âœ… PPO Ã§ok daha uygun, Ã§Ã¼nkÃ¼ sÃ¼rekli politikalarÄ± doÄŸrudan Ã¶ÄŸrenebilir\n",
    "\n",
    "ğŸ§  Bu proje, **Politika GradyanÄ± yÃ¶ntemleri** olan PPO'nun neden sÃ¼rekli kontrol problemlerinde tercih edildiÄŸini ve DQN'u yanlÄ±ÅŸ ortama zorladÄ±ÄŸÄ±nÄ±zda ne olduÄŸunu anlamanÄ±za yardÄ±mcÄ± olacak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88c908",
   "metadata": {},
   "source": [
    "---\n",
    "Bu proje iÃ§in ihtiyaÃ§ duyacaÄŸÄ±mÄ±z tÃ¼m paketleri iÃ§e aktararak baÅŸlayalÄ±m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98dd7902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T17:50:40.753410Z",
     "iopub.status.busy": "2026-01-29T17:50:40.752786Z",
     "iopub.status.idle": "2026-01-29T17:50:47.837163Z",
     "shell.execute_reply": "2026-01-29T17:50:47.836372Z",
     "shell.execute_reply.started": "2026-01-29T17:50:40.753395Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e830f",
   "metadata": {},
   "source": [
    "---\n",
    "### BÃ¶lÃ¼m 1 : CarRacing Ã¼zerinde DQN\n",
    "\n",
    "Bu bÃ¶lÃ¼mde, ÅŸimdiye kadar Ã¶ÄŸrendiÄŸiniz her ÅŸeyi uygulayacaksÄ±nÄ±z â€” ancak bu sefer Gymnasium'dan `CarRacing-v3` ortamÄ± Ã¼zerinde.\n",
    "\n",
    "#### ğŸ§  Ä°lginÃ§ olan ne?  \n",
    "â†’ `CarRacing-v3` **sÃ¼rekli** eylem uzayÄ±na sahip.  \n",
    "â†’ DQN sadece **ayrÄ±k** eylemlerle Ã§alÄ±ÅŸÄ±r.  \n",
    "\n",
    "Bu gÃ¶rev DQN'un temel bir sÄ±nÄ±rÄ±nÄ± vurgular.\n",
    "\n",
    "#### ğŸ“ Ä°zlenecek AdÄ±mlar:\n",
    "\n",
    "1. ğŸš— OrtamÄ± YÃ¼kle: OrtamÄ± yÃ¼klemek iÃ§in `gym.make('CarRacing-v3')` kullan.\n",
    "2. ğŸ§© DummyVecEnv ile Sar.\n",
    "3. âš™ï¸ DQN Modelini BaÅŸlat.\n",
    "4. ğŸªµ EpisodeRewardLogger Kullan:\n",
    "    - Her bÃ¶lÃ¼mÃ¼n sonunda Ã¶dÃ¼lleri kaydetmek iÃ§in aÅŸaÄŸÄ±da saÄŸlanan Ã¶zel geri Ã§aÄŸÄ±rma.\n",
    "    - `.learn()` Ã§aÄŸrÄ±lÄ±rken geri Ã§aÄŸÄ±rma olarak geÃ§irin.\n",
    "5. â±ï¸ 10.000 Zaman AdÄ±mÄ± iÃ§in EÄŸit\n",
    "\n",
    "#### âš ï¸ Ne Olur?\n",
    "\n",
    "```python\n",
    "ValueError: DQN policies can only be used with environments that have a discrete action space. Your action space is of type Box.\n",
    "```\n",
    "\n",
    "Bu hatayÄ± gÃ¶rdÃ¼ÄŸÃ¼nÃ¼zde, bir sonraki bÃ¶lÃ¼me geÃ§meye hazÄ±rsÄ±nÄ±z!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e4aaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T17:50:47.838168Z",
     "iopub.status.busy": "2026-01-29T17:50:47.837893Z",
     "iopub.status.idle": "2026-01-29T17:50:47.844147Z",
     "shell.execute_reply": "2026-01-29T17:50:47.843115Z",
     "shell.execute_reply.started": "2026-01-29T17:50:47.838153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a custom callback to log rewards at the end of each episode.\n",
    "class EpisodeRewardLogger(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(EpisodeRewardLogger, self).__init__(verbose)\n",
    "        # List to store the total rewards for each episode.\n",
    "        self.episode_rewards = []\n",
    "        # Variable to accumulate rewards for the current episode.\n",
    "        self.episode_reward = 0\n",
    "\n",
    "    # This method is called after every step taken in the environment.\n",
    "    def _on_step(self) -> bool:\n",
    "        # Add the reward from the current step to the episode reward accumulator.\n",
    "        self.episode_reward += self.locals['rewards'][0]\n",
    "\n",
    "        # Check if the episode is done (i.e., the environment has reached a terminal state).\n",
    "        if self.locals['dones'][0]:\n",
    "            # If the episode is done, append the accumulated reward to the episode_rewards list.\n",
    "            self.episode_rewards.append(self.episode_reward)\n",
    "            # Reset the episode reward accumulator to zero for the next episode.\n",
    "            self.episode_reward = 0\n",
    "\n",
    "        # Return True to continue training, False would stop the training.\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b951f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T17:50:47.845219Z",
     "iopub.status.busy": "2026-01-29T17:50:47.844983Z",
     "iopub.status.idle": "2026-01-29T17:50:48.352436Z",
     "shell.execute_reply": "2026-01-29T17:50:48.350799Z",
     "shell.execute_reply.started": "2026-01-29T17:50:47.845192Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/langchain-env/lib/python3.12/site-packages/gymnasium/envs/box2d/bipedal_walker.py:15\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         circleShape,\n\u001b[1;32m     18\u001b[0m         contactListener,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         revoluteJointDef,\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Car Racing environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCarRacing-v3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Wrap the environment to be compatible with Stable Baselines3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])  \u001b[38;5;66;03m# Ensures correct handling of single environment\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/langchain-env/lib/python3.12/site-packages/gymnasium/envs/registration.py:696\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[1;32m    699\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/langchain-env/lib/python3.12/site-packages/gymnasium/envs/registration.py:544\u001b[0m, in \u001b[0;36mload_env_creator\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 544\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:999\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/langchain-env/lib/python3.12/site-packages/gymnasium/envs/box2d/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbipedal_walker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcar_racing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CarRacing\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunar_lander\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001b[0;32m~/.pyenv/versions/langchain-env/lib/python3.12/site-packages/gymnasium/envs/box2d/bipedal_walker.py:25\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         circleShape,\n\u001b[1;32m     18\u001b[0m         contactListener,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         revoluteJointDef,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox2D is not installed, you can install it by run `pip install swig` followed by `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgymnasium[box2d]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygame\u001b[39;00m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`"
     ]
    }
   ],
   "source": [
    "# Load the Car Racing environment\n",
    "env = gym.make('CarRacing-v3', render_mode=None)\n",
    "\n",
    "# Wrap the environment to be compatible with Stable Baselines3\n",
    "env = DummyVecEnv([lambda: env])  # Ensures correct handling of single environment\n",
    "\n",
    "# Initialize the DQN model\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Set the number of timesteps for training\n",
    "timesteps = 10000\n",
    "\n",
    "# Initialize the EpisodeRewardLogger callback to track rewards\n",
    "dqn_episode_reward_logger = EpisodeRewardLogger()\n",
    "\n",
    "# Start measuring training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=timesteps, callback=dqn_episode_reward_logger)\n",
    "\n",
    "# End measuring training time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total training time\n",
    "dqn_training_time = end_time - start_time\n",
    "\n",
    "# Define model save path\n",
    "model_path = \"dqn_car_racing_model\"\n",
    "\n",
    "# Save the trained model\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Model trained and saved to\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c2ba9",
   "metadata": {},
   "source": [
    "### â“ Bu neden hata veriyor?\n",
    "\n",
    "- â†’ **DQN** **ayrÄ±k eylem kÃ¼mesi** gerektirir â€” *sol*, *saÄŸ*, *yukarÄ±*, *aÅŸaÄŸÄ±* gibi.  \n",
    "- â†’ **CarRacing** **sÃ¼rekli eylem uzayÄ±** kullanÄ±r â€” *direksiyon*, *hÄ±zlanma* ve *frenleme* iÃ§in gerÃ§el deÄŸerlerle.\n",
    "\n",
    "ğŸ“‰ Bu yÃ¼zden **DQN bu ortamda Ã§alÄ±ÅŸmaz** â€” sÃ¼rekli kontrol gÃ¶revleri iÃ§in inÅŸa edilmemiÅŸ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a84f2",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ§  BÃ¶lÃ¼m 2: Araba YarÄ±ÅŸÄ±nda Politika GradyanÄ±\n",
    "\n",
    "Bu bÃ¶lÃ¼mde, daha Ã¶nce yaptÄ±ÄŸÄ±nÄ±z iÅŸlemi tekrarlayacaksÄ±nÄ±z â€” ancak bu sefer **Politika GradyanÄ± yÃ¶ntemi** kullanarak:  \n",
    "Stable Baselines3'ten `MlpPolicy` ile `PPO` modeli.\n",
    "\n",
    "#### ğŸ“ Ä°zlenecek AdÄ±mlar:\n",
    "\n",
    "1. ğŸš— OrtamÄ± YÃ¼kle: OrtamÄ± yÃ¼klemek iÃ§in `gym.make('CarRacing-v3')` kullan.\n",
    "2. ğŸ§© DummyVecEnv ile Sar.\n",
    "3. âš™ï¸ PPO Modelini BaÅŸlat.\n",
    "4. ğŸªµ EpisodeRewardLogger Kullan:\n",
    "    - Her bÃ¶lÃ¼mÃ¼n sonunda Ã¶dÃ¼lleri kaydetmek iÃ§in aÅŸaÄŸÄ±da saÄŸlanan Ã¶zel geri Ã§aÄŸÄ±rma.\n",
    "    - `.learn()` Ã§aÄŸrÄ±lÄ±rken geri Ã§aÄŸÄ±rma olarak geÃ§irin.\n",
    "5. â±ï¸ 10.000 Zaman AdÄ±mÄ± iÃ§in EÄŸit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76117ab5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-29T17:50:48.352908Z",
     "iopub.status.idle": "2026-01-29T17:50:48.353168Z",
     "shell.execute_reply": "2026-01-29T17:50:48.353061Z",
     "shell.execute_reply.started": "2026-01-29T17:50:48.353051Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Load environment\n",
    "env = gym.make('CarRacing-v3', render_mode=None)\n",
    "\n",
    "# Wrap the environment to be compatible with SB3\n",
    "env = DummyVecEnv([lambda: env])  # Lambda function to ensure correct environment handling\n",
    "\n",
    "# Load the model, match it with the environment, set a policy, add a logging location\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Set training timesteps\n",
    "timesteps = 10000\n",
    "\n",
    "# Initialize the callback\n",
    "pg_episode_reward_logger = EpisodeRewardLogger()\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=timesteps, callback=pg_episode_reward_logger)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total training time\n",
    "pg_training_time = end_time - start_time\n",
    "\n",
    "# Define model save path\n",
    "model_path = \"ppo_lunar_lander_model\"\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Model trained and saved to\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597f248",
   "metadata": {},
   "source": [
    "ğŸ‘‰ EÄŸitim ne kadar sÃ¼rdÃ¼?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0e475",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-29T17:50:48.354220Z",
     "iopub.status.idle": "2026-01-29T17:50:48.354454Z",
     "shell.execute_reply": "2026-01-29T17:50:48.354363Z",
     "shell.execute_reply.started": "2026-01-29T17:50:48.354354Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Training completed in {pg_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f197486",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Ã–dÃ¼lleri zaman iÃ§inde Ã§izin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b173e8c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-29T17:50:48.356448Z",
     "iopub.status.idle": "2026-01-29T17:50:48.356696Z",
     "shell.execute_reply": "2026-01-29T17:50:48.356604Z",
     "shell.execute_reply.started": "2026-01-29T17:50:48.356595Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(pg_episode_reward_logger.episode_rewards, label='PG Rewards')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4b20a",
   "metadata": {},
   "source": [
    "#### ğŸ“Š Politika GradyanÄ± EÄŸitim GÃ¼nlÃ¼ÄŸÃ¼ Metriklerini Anlama\n",
    "\n",
    "PPO gibi algoritmalarla eÄŸitim yaparken, Ã§eÅŸitli gÃ¼nlÃ¼k metrikleri performansÄ± ve eÄŸitim kararlÄ±lÄ±ÄŸÄ±nÄ± takip etmenize yardÄ±mcÄ± olur.\n",
    "\n",
    "#### â±ï¸ Zamanla Ä°lgili Metrikler\n",
    "\n",
    "- **fps** â†’ Saniye baÅŸÄ±na kare â€” model ne kadar hÄ±zlÄ± eÄŸitiliyor. YÃ¼ksek = daha iyi.  \n",
    "- **iterations** â†’ Tamamlanan parametre gÃ¼ncelleme dÃ¶ngÃ¼sÃ¼ sayÄ±sÄ±.  \n",
    "- **time_elapsed** â†’ EÄŸitimin baÅŸlamasÄ±ndan bu yana geÃ§en toplam sÃ¼re (saniye).  \n",
    "- **total_timesteps** â†’ Ajan tarafÄ±ndan deneyimlenen toplam ortam adÄ±mÄ± sayÄ±sÄ±.\n",
    "\n",
    "#### ğŸ§  EÄŸitim SÃ¼reci Metrikleri\n",
    "\n",
    "- **approx_kl** â†’ Bir gÃ¼ncellemeden sonra politikanÄ±n ne kadar deÄŸiÅŸtiÄŸi.  \n",
    "  - DÃ¼ÅŸÃ¼k = daha kararlÄ± Ã¶ÄŸrenme.  \n",
    "- **clip_fraction** â†’ PPO'nun gÃ¼ncelleme kÄ±rpmasÄ±nÄ±n ne sÄ±klÄ±kta uygulandÄ±ÄŸÄ±.  \n",
    "- **clip_range** â†’ Politika gÃ¼ncellemelerini kÄ±rpmak iÃ§in kullanÄ±lan aralÄ±k (ani deÄŸiÅŸiklikleri Ã¶nler).  \n",
    "- **entropy_loss** â†’ Eylem seÃ§imindeki rastgeleliÄŸi Ã¶lÃ§er.  \n",
    "  - YÃ¼ksek = daha fazla keÅŸif.  \n",
    "- **explained_variance** â†’ DeÄŸer tahminlerinin gerÃ§ek getirilerle ne kadar eÅŸleÅŸtiÄŸi.  \n",
    "  - 1'e yakÄ±n = daha iyi.  \n",
    "- **learning_rate** â†’ AÄŸÄ±rlÄ±k gÃ¼ncellemelerinin boyutunu kontrol eder.  \n",
    "- **loss** â†’ Genel eÄŸitim kaybÄ± â€” iyileÅŸmeyi takip etmeye yardÄ±mcÄ± olur.  \n",
    "- **n_updates** â†’ Toplam model aÄŸÄ±rlÄ±ÄŸÄ± gÃ¼ncellemesi sayÄ±sÄ±.  \n",
    "- **policy_gradient_loss** â†’ PolitikanÄ±n ne kadar iyileÅŸtiÄŸini gÃ¶sterir.  \n",
    "- **value_loss** â†’ DeÄŸer fonksiyonu tahminlerinin ne kadar doÄŸru olduÄŸunu Ã¶lÃ§er.\n",
    "\n",
    "#### ğŸ” Bu Metrikleri NasÄ±l YorumlarÄ±z\n",
    "\n",
    "- **YÃ¼ksek `entropy_loss`** â†’ Ajan daha fazla keÅŸfediyor (Ã§ok rastgele olabilir).  \n",
    "- **DÃ¼ÅŸÃ¼k `explained_variance`** â†’ DeÄŸer tahminleri yanlÄ±ÅŸ.  \n",
    "- **Azalan `loss`** â†’ Zaman iÃ§inde etkili Ã¶ÄŸrenme olduÄŸunu gÃ¶sterir.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58235964",
   "metadata": {},
   "source": [
    "### ğŸ§  Politika GradyanÄ± Neden CarRacing iÃ§in Ä°deal\n",
    "\n",
    "CarRacing pÃ¼rÃ¼zsÃ¼z ve hassas kontrol gerektirir â€” bu da **Politika GradyanÄ± yÃ¶ntemleri** olan **PPO**'yu mÃ¼kemmel uyum haline getirir.\n",
    "\n",
    "#### 1. ğŸ¯ SÃ¼rekli Eylemler iÃ§in TasarlandÄ±  \n",
    "- PPO **gerÃ§ek deÄŸerli eylemleri** doÄŸrudan iÅŸler.  \n",
    "- CarRacing'de, ajan sadece sol veya saÄŸÄ± seÃ§mek deÄŸil, *ne kadar direksiyon kÄ±rÄ±lacaÄŸÄ±nÄ±*, *ne kadar sert fren yapÄ±lacaÄŸÄ±nÄ±* ve *ne kadar gaz verileceÄŸini* seÃ§mesi gerekir.\n",
    "\n",
    "#### 2. ğŸ§  PolitikayÄ± DoÄŸrudan Ã–ÄŸrenir  \n",
    "- Eylemlerin deÄŸerini tahmin eden DQN'un aksine, PPO *nasÄ±l* davranacaÄŸÄ±nÄ± Ã¶ÄŸrenir.  \n",
    "- Bu, yÃ¼ksek hÄ±zlÄ± sÃ¼rÃ¼ÅŸ ortamlarÄ±nda kritik olan **daha esnek ve uyarlanabilir davranÄ±ÅŸlara** olanak tanÄ±r.\n",
    "\n",
    "#### 3. ğŸª¶ PÃ¼rÃ¼zsÃ¼z ve Hassas Kontrol  \n",
    "- PPO **ince ayarlÄ± kararlarÄ±** destekler â€” sÃ¼rÃ¼ÅŸ gÃ¶revlerinde gereken ince ayarlamalar iÃ§in mÃ¼kemmel.  \n",
    "- ArtÄ±k ani, hep ya da hiÃ§ hareketler yok.\n",
    "\n",
    "---\n",
    "\n",
    "### âŒ DQN Neden Burada Ä°yi Bir Uyum DeÄŸil\n",
    "\n",
    "- **DQN ayrÄ±k eylem uzayÄ± gerektirir** (Ã¶r. *yukarÄ±*, *aÅŸaÄŸÄ±*, *sol*, *saÄŸ*).  \n",
    "- CarRacing **sÃ¼rekli eylem uzayÄ±** kullanÄ±r â€” eylemlerin gerÃ§el sayÄ±lar olduÄŸu.\n",
    "\n",
    "DQN kullanmak iÃ§in, direksiyon/fren/gaz kombinasyonlarÄ±nÄ±n tamamÄ±nÄ± **ayrÄ±klaÅŸtÄ±rmanÄ±z** gerekir:  \n",
    "ğŸ§± Verimsiz ve nadiren etkili olan bir geÃ§ici Ã§Ã¶zÃ¼m.\n",
    "\n",
    "---\n",
    "\n",
    "### âš–ï¸ Ã–zet: Politika GradyanÄ±nÄ±n ParladÄ±ÄŸÄ± Yer BurasÄ±\n",
    "\n",
    "| YÃ¶ntem           | CarRacing'deki GÃ¼cÃ¼                                    |\n",
    "|------------------|-----------------------------------------------------------|\n",
    "| ğŸ§  Politika GradyanÄ± | SÃ¼rekli eylemleri doÄŸrudan Ã¶ÄŸrenir â€” ayrÄ±klaÅŸtÄ±rma gerekmez. |\n",
    "| âŒ DQN             | SÃ¼rekli eylemler iÃ§in inÅŸa edilmemiÅŸ â€” uyum saÄŸlamakta zorlanÄ±r.         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (langchain-env)",
   "language": "python",
   "name": "langchain-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
